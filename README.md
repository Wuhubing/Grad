# ğŸ§  Knowledge Coupling Analysis for LLaMA-2 Models

<div align="center">

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-v2.0+-red.svg)
![CUDA](https://img.shields.io/badge/CUDA-GPU%20Accelerated-green.svg)
![HuggingFace](https://img.shields.io/badge/ğŸ¤—%20HuggingFace-Transformers-orange.svg)

**å¤šè·³æ¨ç†çŸ¥è¯†ç‰‡æ®µè€¦åˆåˆ†æç³»ç»Ÿ**  
*Multi-hop Reasoning Knowledge Piece Coupling Analysis*

</div>

## ğŸ“ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªGPUä¼˜åŒ–çš„çŸ¥è¯†ç‰‡æ®µé—´è€¦åˆåº¦è®¡ç®—å’Œæ¶Ÿæ¼ªæ•ˆåº”åˆ†æç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºç ”ç©¶å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLaMA-2ã€GPT-2ç­‰ï¼‰ä¸­çŸ¥è¯†çš„ç›¸äº’ä¾èµ–å…³ç³»ã€‚

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

- **ğŸ”¬ æ¢¯åº¦ç›¸ä¼¼åº¦åˆ†æ**: è®¡ç®—çŸ¥è¯†ç‰‡æ®µé—´çš„å‚æ•°ç©ºé—´é‡å åº¦é‡
- **ğŸŒŠ æ¶Ÿæ¼ªæ•ˆåº”é¢„æµ‹**: åŸºäºè€¦åˆå¼ºåº¦é¢„æµ‹çŸ¥è¯†ç¼–è¾‘çš„è¿é”ååº”
- **ğŸš€ GPUåŠ é€Ÿè®¡ç®—**: 15xæ€§èƒ½æå‡çš„GPUä¼˜åŒ–å®ç°
- **ğŸ“Š å¤šæ•°æ®é›†æ”¯æŒ**: æ”¯æŒHotpotQAã€MuSiQueã€WikiHopã€Bamboogleç­‰å¤šè·³æ¨ç†æ•°æ®é›†
- **ğŸ¤– å¤šæ¨¡å‹å…¼å®¹**: æ”¯æŒLLaMA-2 (7B/13B/70B) å’Œ GPT-2 (small/medium/large/xl)

### ğŸ§® æ ¸å¿ƒç®—æ³•

```
GradSim(i,j) = cos(âˆ‡_Î¸ log P(a_i|q_i), âˆ‡_Î¸ log P(a_j|q_j))
```

é€šè¿‡è®¡ç®—ä¸åŒçŸ¥è¯†ç‰‡æ®µå¯¹åº”ç­”æ¡ˆçš„æ¢¯åº¦å‘é‡ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œé‡åŒ–çŸ¥è¯†é—´çš„è€¦åˆå¼ºåº¦ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/Wuhubing/Grad.git
cd Grad

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### åŸºç¡€ä½¿ç”¨

```bash
# ä½¿ç”¨æµ‹è¯•æ•°æ®è¿è¡ŒçŸ¥è¯†è€¦åˆåˆ†æ
python knowledge_coupling_mvp.py --hotpot_data test_hotpot_20.json --max_samples 20

# ä¸‹è½½å¤šè·³æ¨ç†æ•°æ®é›†
python multihop_dataset_downloader.py

# å¤šæ¨¡å‹æµ‹è¯•
python test_multi_model.py
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
Grad/
â”œâ”€â”€ ğŸ“„ knowledge_coupling_mvp.py      # æ ¸å¿ƒåˆ†æç³»ç»Ÿ
â”œâ”€â”€ ğŸ“„ multihop_dataset_downloader.py # å¤šæ•°æ®é›†ä¸‹è½½å™¨
â”œâ”€â”€ ğŸ“„ test_multi_model.py           # å¤šæ¨¡å‹æµ‹è¯•è„šæœ¬
â”œâ”€â”€ ğŸ“„ demo_results.py               # ç»“æœæ¼”ç¤ºè„šæœ¬
â”œâ”€â”€ ğŸ“„ test_downloader.py            # ä¸‹è½½å™¨æµ‹è¯•
â”œâ”€â”€ ğŸ“„ requirements.txt              # é¡¹ç›®ä¾èµ–
â”œâ”€â”€ ğŸ“„ test_hotpot_20.json          # æµ‹è¯•æ•°æ®é›†
â””â”€â”€ ğŸ“š README_MVP.md                 # MVPè¯¦ç»†æ–‡æ¡£
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### 1. çŸ¥è¯†è€¦åˆåˆ†æå™¨ (`knowledge_coupling_mvp.py`)

- **å¤šæ¨¡å‹æ”¯æŒ**: è‡ªåŠ¨æ£€æµ‹å¹¶é€‚é…LLaMA-2å’ŒGPT-2æ¶æ„
- **GPUä¼˜åŒ–**: å…¨æµç¨‹GPUåŠ é€Ÿï¼Œæ”¯æŒå¤§è§„æ¨¡åˆ†æ
- **æ™ºèƒ½å±‚é€‰æ‹©**: æ ¹æ®æ¨¡å‹ç±»å‹è‡ªåŠ¨é€‰æ‹©ç›®æ ‡å±‚

### 2. å¤šæ•°æ®é›†ä¸‹è½½å™¨ (`multihop_dataset_downloader.py`)

æ”¯æŒçš„æ•°æ®é›†:
- **HotpotQA**: ç»´åŸºç™¾ç§‘å¤šè·³æ¨ç† (~500MB)
- **MuSiQue**: å•ä¸€æ”¯æŒäº‹å®å¤šè·³é—®ç­” (~100MB) 
- **WikiHop**: å¤šæ–‡æ¡£é˜…è¯»ç†è§£ (~200MB)
- **Bamboogle**: åˆæˆå¤šè·³é—®ç­” (~50MB)

### 3. å®éªŒéªŒè¯è„šæœ¬

- `test_multi_model.py`: å¤šæ¨¡å‹å…¼å®¹æ€§æµ‹è¯•
- `demo_results.py`: è¯¦ç»†ç»“æœå±•ç¤º
- `test_downloader.py`: æ•°æ®é›†ä¸‹è½½æµ‹è¯•

## ğŸ“Š å®éªŒç»“æœ

### æ€§èƒ½æŒ‡æ ‡

- **å¤„ç†é€Ÿåº¦**: 23.44 samples/sec (GPUåŠ é€Ÿ)
- **å†…å­˜ä½¿ç”¨**: ~1.4GB GPUå†…å­˜ (NVIDIA A40)
- **æ¢¯åº¦ç»´åº¦**: 28,320,768 å‚æ•°
- **è€¦åˆè®¡ç®—**: å®æ—¶GPUçŸ©é˜µè¿ç®—

### åˆ†æè¾“å‡º

ç³»ç»Ÿç”Ÿæˆ9ä¸ªç»´åº¦çš„ç»¼åˆåˆ†æç»“æœ:

1. **metadata**: æ¨¡å‹ä¿¡æ¯å’Œå¤„ç†è¯¦æƒ…
2. **knowledge_pieces**: çŸ¥è¯†ç‰‡æ®µè¯¦ç»†ä¿¡æ¯
3. **gradient_analysis**: æ¢¯åº¦è®¡ç®—ç»“æœ
4. **coupling_analysis**: è€¦åˆå¼ºåº¦ç»Ÿè®¡
5. **high_coupling_pairs**: é«˜è€¦åˆå¯¹æ’å
6. **cross_pot_analysis**: è·¨é—®é¢˜è€¦åˆæ¨¡å¼
7. **generated_files**: ç”Ÿæˆæ–‡ä»¶è·¯å¾„
8. **gpu_performance**: GPUæ€§èƒ½æŒ‡æ ‡
9. **experiment_readiness**: å®éªŒå‡†å¤‡çŠ¶æ€

## ğŸ”¬ æŠ€æœ¯åŸç†

### æ¢¯åº¦æå–
é’ˆå¯¹æ¯ä¸ªçŸ¥è¯†ç‰‡æ®µçš„çœŸå®ç­”æ¡ˆtokenè®¡ç®—æ¢¯åº¦:
```python
âˆ‡_Î¸ log P(answer|question)
```

### è€¦åˆåº¦é‡
ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦é‡åŒ–çŸ¥è¯†ç‰‡æ®µé—´çš„å‚æ•°ç©ºé—´é‡å :
```python
coupling = cosine_similarity(grad_i, grad_j)
```

### æ¶Ÿæ¼ªæ•ˆåº”é¢„æµ‹
åŸºäºè€¦åˆå¼ºåº¦é¢„æµ‹çŸ¥è¯†ç¼–è¾‘å¯¹å…¶ä»–ç‰‡æ®µçš„å½±å“:
```python
ripple_strength = coupling_strength Ã— edit_magnitude
```

## ğŸ¨ å¯è§†åŒ–

ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ:
- ğŸ“ˆ è€¦åˆå¼ºåº¦çƒ­å›¾
- ğŸ“Š è€¦åˆåˆ†å¸ƒç»Ÿè®¡
- ğŸŒŠ æ¶Ÿæ¼ªæ•ˆåº”é¢„æµ‹å›¾è¡¨

## ğŸ› ï¸ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„
```bash
python knowledge_coupling_mvp.py \
    --hotpot_data your_data.json \
    --model_path "meta-llama/Llama-2-7b-hf" \
    --max_samples 100 \
    --device cuda
```

### æ‰¹é‡æ•°æ®é›†å¤„ç†
```bash
# ä¸‹è½½æ‰€æœ‰æ”¯æŒçš„æ•°æ®é›†
python multihop_dataset_downloader.py
```

### ç»“æœåˆ†æ
```python
from demo_results import analyze_detailed_results
results = analyze_detailed_results("gpu_coupling_results/")
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

- **GPUå†…å­˜ç®¡ç†**: æ™ºèƒ½æ‰¹å¤„ç†å’Œå†…å­˜é‡Šæ”¾
- **å¼ é‡æ“ä½œä¼˜åŒ–**: å…¨æµç¨‹GPUå¼ é‡æ“ä½œ
- **å¹¶è¡Œè®¡ç®—**: çŸ©é˜µè¿ç®—å¹¶è¡ŒåŒ–
- **ç¼“å­˜ç­–ç•¥**: æ¢¯åº¦å’Œæ¨¡å‹è¾“å‡ºç¼“å­˜

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ! è¯·ç¡®ä¿:

1. éµå¾ªç°æœ‰ä»£ç é£æ ¼
2. æ·»åŠ é€‚å½“çš„æµ‹è¯•
3. æ›´æ–°ç›¸å…³æ–‡æ¡£
4. æäº¤å‰è¿è¡Œæµ‹è¯•å¥—ä»¶

## ğŸ“š ç›¸å…³èµ„æº

- [MVPè¯¦ç»†æ–‡æ¡£](README_MVP.md)
- [HuggingFace Transformers](https://huggingface.co/transformers/)
- [PyTorch Documentation](https://pytorch.org/docs/)

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®å’Œæ•°æ®é›†:
- HuggingFace Transformers
- HotpotQA Dataset
- MuSiQue Dataset
- PyTorch Team

---

<div align="center">

**ğŸ§  æ¢ç´¢å¤§è¯­è¨€æ¨¡å‹ä¸­çš„çŸ¥è¯†è€¦åˆå¥¥ç§˜**

Made with â¤ï¸ for AI Research

</div> 